<?xml version="1.0" encoding="UTF-8"?>
<spiderman>
    <property key="duration" value="0" /><!-- 运行时间 0 表示永久，可以给 {n}s {n}m {n}h {n}d -->
    <property key="logger.level" value="DEBUG" /><!-- 日志级别 INFO DEBUG WARN ERROR OFF -->
    <property key="worker.download.size" value="1" /><!-- 下载线程数 -->
    <property key="worker.extract.size" value="1" /><!-- 页面抽取线程数 -->
    <property key="worker.result.size" value="1" /><!-- 结果处理线程数 -->
    <property key="worker.result.handler" value="spiderman.MyResultHandler" /><!-- 自定义结果回调处理类 -->
    <property key="queue.capacity" value="5000" /><!-- 队列大小，0表示无界 -->
    <property key="queue.element.repeatable" value="false" /><!-- 队列元素是否允许重复，默认允许，若不允许，则使用重复检查器在元素入队列前进行检查 -->
    <property key="queue.checker.bdb.file" value="store/checker" /><!-- 检查器需要用到BDb存储 -->
    <property key="queue.zbus.enabled" value="false" /><!-- 队列是否使用ZBus实现, 默认否，若是，可支持分布式处理 -->
    <property key="queue.zbus.server" value="10.8.60.8:15555" /><!-- ZBus服务地址 {IP或域名}:{端口号} -->
    <property key="queue.other.names" value="SPIDERMAN_JSON_RESULT" /><!-- 注册创建其他队列备用 -->
    <!-- <seed>URL地址</seed> --><!-- 写死种子入口的方式 -->
    <script bindings="spiderman.MyBindings"><!-- 使用脚本动态创建方式 -->
    <![CDATA[
    	var K = Java.type("net.kernal.spiderman.K");
    	var kws = K.readLine("keywords.txt");
    	for (var i = 0; i < kws.length; i++) {
    		var kw = kws[i].trim();
    	    var ekw = K.urlEncode(kw);
	        $seeds.add(kw+"-baidu", "http://www.baidu.com/s?wd=" + ekw);
	        $seeds.add(kw+"-baidu-news", "http://news.baidu.com/ns?word=" + ekw);
	        $seeds.add(kw+"-baidu-zhidao", "http://zhidao.baidu.com/search?word=" + ekw);
	    }
	]]>
    </script>
    <extract><!-- 页面抽取规则 -->
        <extractor name="Text" class="net.kernal.spiderman.worker.extract.TextExtractor" isDefault="1" /><!-- 正文抽取器 -->
        <extractor name="Links" class="net.kernal.spiderman.worker.extract.LinksExtractor" /><!-- 链接抽取器 -->
        <filter name="MyFilter" class="spiderman.MyFilter" /><!-- 过滤器 -->
        <page name="网页内容" isUnique="1">
			<url-match-rule type="!contains" value="baidu" />
		</page>
		<page name="发现新网页" isUnique="1" extractor="Links" filter="MyFilter">
			<url-match-rule type="contains" value="baidu" />
		</page>
	</extract>
</spiderman>
